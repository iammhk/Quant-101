{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iammhk/Quant-101/blob/main/Stock_regression_scikit_BigQuery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDR-e1wrJTQI"
      },
      "source": [
        "# Building a Regression Model for a Financial Dataset\n",
        "\n",
        "In this notebook, you will build a simple linear regression model to predict the closing AAPL stock price. The lab objectives are:\n",
        "* Pull data from BigQuery into a Pandas dataframe\n",
        "* Use Matplotlib to visualize data\n",
        "* Use Scikit-Learn to build a regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nny3m465gKkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "defc7caa-28c0-42d7-f522-fa06e3738b2d"
      },
      "source": [
        "!sudo chown -R jupyter:jupyter /home/jupyter/training-data-analyst"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chown: invalid user: ‘jupyter:jupyter’\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "46SWbv9IJTQP",
        "outputId": "365945f6-3c23-4864-e775-ae5fe0fc7a28"
      },
      "source": [
        "!pip install --user google-cloud-bigquery==1.25.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-cloud-bigquery==1.25.0\n",
            "  Downloading google_cloud_bigquery-1.25.0-py2.py3-none-any.whl (169 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 30 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 40 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 169 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-core<2.0dev,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery==1.25.0) (1.26.3)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery==1.25.0) (1.35.0)\n",
            "Collecting google-resumable-media<0.6dev,>=0.5.0\n",
            "  Downloading google_resumable_media-0.5.1-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery==1.25.0) (3.17.3)\n",
            "Requirement already satisfied: six<2.0.0dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery==1.25.0) (1.15.0)\n",
            "Collecting google-cloud-core<2.0dev,>=1.1.0\n",
            "  Downloading google_cloud_core-1.7.2-py2.py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (1.54.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2018.9)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2.23.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (21.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (4.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (3.0.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (1.24.3)\n",
            "Installing collected packages: google-resumable-media, google-cloud-core, google-cloud-bigquery\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-storage 1.18.1 requires google-resumable-media<0.5.0dev,>=0.3.1, but you have google-resumable-media 0.5.1 which is incompatible.\u001b[0m\n",
            "Successfully installed google-cloud-bigquery-1.25.0 google-cloud-core-1.7.2 google-resumable-media-0.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w4twZtQJTQR"
      },
      "source": [
        "**Note**: Restart your kernel to use updated packages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKx5v0n-JTQR"
      },
      "source": [
        "Kindly ignore the deprecation warnings and incompatibility errors related to google-cloud-storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwxNvlLCJTQS",
        "outputId": "a8d578ee-4ad8-4cfc-bfb3-6311d42dd171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: (bq) You do not currently have an active account selected.\n",
            "Please run:\n",
            "\n",
            "  $ gcloud auth login\n",
            "\n",
            "to obtain new credentials.\n",
            "\n",
            "If you have already logged in with a different account:\n",
            "\n",
            "    $ gcloud config set account ACCOUNT\n",
            "\n",
            "to select an already authenticated account to use.\n",
            "ERROR: (bq) You do not currently have an active account selected.\n",
            "Please run:\n",
            "\n",
            "  $ gcloud auth login\n",
            "\n",
            "to obtain new credentials.\n",
            "\n",
            "If you have already logged in with a different account:\n",
            "\n",
            "    $ gcloud config set account ACCOUNT\n",
            "\n",
            "to select an already authenticated account to use.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "bq mk -d ai4f\n",
        "bq load --autodetect --source_format=CSV ai4f.AAPL10Y gs://cloud-training/ai4f/AAPL10Y.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6fc6PFKJTQT"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "plt.rc('figure', figsize=(12, 8.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-dexaipJTQV"
      },
      "source": [
        "## Pull Data from BigQuery\n",
        "\n",
        "In this section we'll use a magic function to query a BigQuery table and then store the output in a Pandas dataframe. A magic function is just an alias to perform a system command. To see documentation on the \"bigquery\" magic function execute the following cell:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfN6tYMAJTQX"
      },
      "source": [
        "The query below selects everything you'll need to build a regression model to predict the closing price of AAPL stock. The model will be very simple for the purposes of demonstrating BQML functionality. The only features you'll use as input into the model are the previous day's closing price and a three day trend value. The trend value can only take on two values, either -1 or +1. If the AAPL stock price has increased over any two of the previous three days then the trend will be +1. Otherwise, the trend value will be -1.\n",
        "\n",
        "Note, the features you'll need can be generated from the raw table `ai4f.AAPL10Y` using Pandas functions. However, it's better to take advantage of the serverless-ness of BigQuery to do the data pre-processing rather than applying the necessary transformations locally.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "1ZgbpfmUJTQZ",
        "outputId": "7cec6626-6a53-463c-ad12-56d8d052195b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "DefaultCredentialsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-728705e7a423>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bigquery'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'df'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'WITH\\n  raw AS (\\n  SELECT\\n    date,\\n    close,\\n    LAG(close, 1) OVER(ORDER BY date) AS min_1_close,\\n    LAG(close, 2) OVER(ORDER BY date) AS min_2_close,\\n    LAG(close, 3) OVER(ORDER BY date) AS min_3_close,\\n    LAG(close, 4) OVER(ORDER BY date) AS min_4_close\\n  FROM\\n    `ai4f.AAPL10Y`\\n  ORDER BY\\n    date DESC ),\\n  raw_plus_trend AS (\\n  SELECT\\n    date,\\n    close,\\n    min_1_close,\\n    IF (min_1_close - min_2_close > 0, 1, -1) AS min_1_trend,\\n    IF (min_2_close - min_3_close > 0, 1, -1) AS min_2_trend,\\n    IF (min_3_close - min_4_close > 0, 1, -1) AS min_3_trend\\n  FROM\\n    raw ),\\n  train_data AS (\\n  SELECT\\n    date,\\n    close,\\n    min_1_close AS day_prev_close,\\n    IF (min_1_trend + min_2_trend + min_3_trend > 0, 1, -1) AS trend_3_day\\n  FROM\\n    raw_plus_trend\\n  ORDER BY\\n    date ASC )\\nSELECT\\n  *\\nFROM\\n  train_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_import_magics.py\u001b[0m in \u001b[0;36mimpl\u001b[0;34m(line, cell, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     return _get_extension_magic(name, module, 'cell',\n\u001b[0;32m---> 88\u001b[0;31m                                 magic_module_loader)(line, cell, **kwargs)\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   \u001b[0;31m# pylint: disable=g-long-lambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/bigquery/magics.py\u001b[0m in \u001b[0;36m_cell_magic\u001b[0;34m(line, query)\u001b[0m\n\u001b[1;32m    445\u001b[0m             )\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m     \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m     client = bigquery.Client(\n\u001b[1;32m    449\u001b[0m         \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/cloud/bigquery/magics.py\u001b[0m in \u001b[0;36mproject\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \"\"\"\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_project\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_project\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_project\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/auth/_default.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffective_project_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaultCredentialsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_HELP_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mDefaultCredentialsError\u001b[0m: Could not automatically determine credentials. Please set GOOGLE_APPLICATION_CREDENTIALS or explicitly create credentials and re-run the application. For more information, please see https://cloud.google.com/docs/authentication/getting-started"
          ]
        }
      ],
      "source": [
        "%%bigquery df\n",
        "WITH\n",
        "  raw AS (\n",
        "  SELECT\n",
        "    date,\n",
        "    close,\n",
        "    LAG(close, 1) OVER(ORDER BY date) AS min_1_close,\n",
        "    LAG(close, 2) OVER(ORDER BY date) AS min_2_close,\n",
        "    LAG(close, 3) OVER(ORDER BY date) AS min_3_close,\n",
        "    LAG(close, 4) OVER(ORDER BY date) AS min_4_close\n",
        "  FROM\n",
        "    `ai4f.AAPL10Y`\n",
        "  ORDER BY\n",
        "    date DESC ),\n",
        "  raw_plus_trend AS (\n",
        "  SELECT\n",
        "    date,\n",
        "    close,\n",
        "    min_1_close,\n",
        "    IF (min_1_close - min_2_close > 0, 1, -1) AS min_1_trend,\n",
        "    IF (min_2_close - min_3_close > 0, 1, -1) AS min_2_trend,\n",
        "    IF (min_3_close - min_4_close > 0, 1, -1) AS min_3_trend\n",
        "  FROM\n",
        "    raw ),\n",
        "  train_data AS (\n",
        "  SELECT\n",
        "    date,\n",
        "    close,\n",
        "    min_1_close AS day_prev_close,\n",
        "    IF (min_1_trend + min_2_trend + min_3_trend > 0, 1, -1) AS trend_3_day\n",
        "  FROM\n",
        "    raw_plus_trend\n",
        "  ORDER BY\n",
        "    date ASC )\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-5SLzgkJTQa"
      },
      "source": [
        "View the first five rows of the query's output. Note that the object `df` containing the query output is a Pandas Dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzFE-O2fJTQb"
      },
      "outputs": [],
      "source": [
        "print(type(df))\n",
        "df.dropna(inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfPD9CfHJTQb"
      },
      "source": [
        "## Visualize data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48p74kKwJTQc"
      },
      "source": [
        "The simplest plot you can make is to show the closing stock price as a time series. Pandas DataFrames have built in plotting funtionality based on Matplotlib. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4p1UoYmMJTQc"
      },
      "outputs": [],
      "source": [
        "df.plot(x='date', y='close');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEv5lEY3JTQd"
      },
      "source": [
        "You can also embed the `trend_3_day` variable into the time series above. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqfrWQ13JTQd"
      },
      "outputs": [],
      "source": [
        "start_date = '2018-06-01'\n",
        "end_date = '2018-07-31'\n",
        "\n",
        "plt.plot(\n",
        "    'date', 'close', 'k--',\n",
        "    data = (\n",
        "        df.loc[pd.to_datetime(df.date).between(start_date, end_date)]\n",
        "    )\n",
        ")\n",
        "\n",
        "plt.scatter(\n",
        "    'date', 'close', color='b', label='pos trend', \n",
        "    data = (\n",
        "        df.loc[df.trend_3_day == 1 & pd.to_datetime(df.date).between(start_date, end_date)]\n",
        "    )\n",
        ")\n",
        "\n",
        "plt.scatter(\n",
        "    'date', 'close', color='r', label='neg trend',\n",
        "    data = (\n",
        "        df.loc[(df.trend_3_day == -1) & pd.to_datetime(df.date).between(start_date, end_date)]\n",
        "    )\n",
        ")\n",
        "\n",
        "plt.legend()\n",
        "plt.xticks(rotation = 90);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS3WZwrKJTQe"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rAyH9N0JTQe"
      },
      "source": [
        "## Build a Regression Model in Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vluc2RdMJTQf"
      },
      "source": [
        "In this section you'll train a linear regression model to predict AAPL closing prices when given the previous day's closing price `day_prev_close` and the three day trend `trend_3_day`. A training set and test set are created by sequentially splitting the data after 2000 rows. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwKBl3swJTQf"
      },
      "outputs": [],
      "source": [
        "features = ['day_prev_close', 'trend_3_day']\n",
        "target = 'close'\n",
        "\n",
        "X_train, X_test = df.loc[:2000, features], df.loc[2000:, features]\n",
        "y_train, y_test = df.loc[:2000, target], df.loc[2000:, target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSvpzkCYJTQg"
      },
      "outputs": [],
      "source": [
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression(fit_intercept=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqtWvQFvJTQg"
      },
      "outputs": [],
      "source": [
        "# Train the model using the training set\n",
        "regr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTklD_zdJTQg"
      },
      "outputs": [],
      "source": [
        "# Make predictions using the testing set\n",
        "y_pred = regr.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zs-chDNEJTQh"
      },
      "outputs": [],
      "source": [
        "# The mean squared error\n",
        "print('Root Mean Squared Error: {0:.2f}'.format(np.sqrt(mean_squared_error(y_test, y_pred))))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance Score: {0:.2f}'.format(r2_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBEsF4-AJTQh"
      },
      "outputs": [],
      "source": [
        "plt.scatter(y_test, y_pred)\n",
        "plt.plot([140, 240], [140, 240], 'r--', label='perfect fit')\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqMZfDR-JTQh"
      },
      "source": [
        "The model's predictions are more or less in line with the truth. However, the utility of the model depends on the business context (i.e. you won't be making any money with this model). It's fair to question whether the variable `trend_3_day` even adds to the performance of the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4Jqx25GJTQi"
      },
      "outputs": [],
      "source": [
        "print('Root Mean Squared Error: {0:.2f}'.format(np.sqrt(mean_squared_error(y_test, X_test.day_prev_close))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uKrXD2cJTQi"
      },
      "source": [
        "Indeed, the RMSE is actually lower if we simply use the previous day's closing value as a prediction! Does increasing the number of days included in the trend improve the model? Feel free to create new features and attempt to improve model performance!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "Stock_regression_scikit_BigQuery.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}